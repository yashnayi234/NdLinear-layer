![ensemble_logo](https://github.com/user-attachments/assets/ddac6b20-98a7-44c9-a912-35678a26da9b)

# NdLinear CNN Experiments on CIFARâ€‘10 & Fashionâ€‘MNIST 

> **Goal**Â Â Â Evaluate the parameterâ€‘efficient **NdLinear** layer against a standard convolutional baseline on two vision datasets and measure the tradeâ€‘offs in accuracy, memory, and speed.

---

## 1Â Â Project Structure

```
.
â”œâ”€â”€ NdLinear - CIFAR10 Ensemble AI.ipynb      # BaselineÂ vsÂ NdLinear on CIFARâ€‘10
â”œâ”€â”€ Ensemable AI - NdLinear.ipynb             # NdLinear on Fashionâ€‘MNIST
â”œâ”€â”€ results/
â”‚Â Â  â”œâ”€â”€ cifar10_comparison_results.pkl        # Pickled dict with metrics & curves
â”‚Â Â  â””â”€â”€ fashion_mnist_ndlinear_results.pkl    # Pickled dict with metrics & curves
â””â”€â”€ ndlinear/                                 # Custom NdLinear layer implementation
```

---

## 2Â Â Setup

```bash
# Clone and create an env (conda or venv)
conda create -n ndlinear python=3.10 -y
conda activate ndlinear

# Core dependencies
pip install torch torchvision tqdm matplotlib psutil

# (Optional) Install the NdLinear layer if published on PyPI
pip install ndlinear
```

> **Hardware used:** NVIDIAÂ T4 GPU (Google Colab) for all runs.

---

## 3Â Â Running the Experiments

| Task                          | Notebook                               | Quick start                                 |
| ----------------------------- | -------------------------------------- | ------------------------------------------- |
| CIFARâ€‘10 baseline vsÂ NdLinear | `NdLinear - CIFAR10 Ensemble AI.ipynb` | Run all cells, \~25Â epochs (â‰ˆÂ 10Â min on T4) |
| Fashionâ€‘MNIST with NdLinear   | `Ensemable AI - NdLinear.ipynb`        | Run all cells, \~15Â epochs (â‰ˆÂ 3Â min on T4)  |

Each notebook saves a **`results/*.pkl`** file containing loss/accuracy curves, epochâ€‘level timing, and memory usage so you can reload and plot without reâ€‘training.

---

## 4Â Â Model Architectures

| Layer              | Baseline CNN                           | NdLinear CNN                                                                      |
| ------------------ | -------------------------------------- | --------------------------------------------------------------------------------- |
| Conv/Linear blocks | Standard `Conv2d`Â +Â `ReLU`Â +Â `MaxPool` | Replace all `Conv2d` layers with **`NdLinear`** (rankâ€‘decomposed linear operator) |
| Classifier head    | 2Â Ã—Â `Linear` + `ReLU`                  | Same head                                                                         |
| Params             | **620â€¯k**                              | **104â€¯k**                                                                         |

NdLinear factorises spatial kernels into a lowâ€‘rank tensor product, dramatically cutting weights while retaining expressive power.

---

## 5Â Â Results

### 5.1Â Â CIFARâ€‘10 (10Â classes, 32Ã—32 RGB)

| Metric                     | Baseline |    NdLinear | Î”                    |
| -------------------------- | -------: | ----------: | -------------------- |
| **Params**                 |  620â€¯362 |     104â€¯094 | **â€“83â€¯%** â†“          |
| **Best acc.**              |  78.73â€¯% | **80.24â€¯%** | **+1.51â€¯pp** â†‘       |
| **AvgÂ epochÂ time**         |  10.60â€¯s |     10.62â€¯s | +0.02â€¯s (negligible) |
| **AvgÂ GPUÂ mem**            |  0.04Â MB | **0.01Â MB** | â€“0.03Â MB â†“           |
| **EpochsÂ toÂ 90â€¯%Â of best** |    **6** |           7 | â€“1Â epoch slower      |

<details>
<summary>ðŸ“ˆÂ Training curves & radar plot (generated by notebook)</summary>

The notebook renders:

### FashionMNIST
![image](https://github.com/user-attachments/assets/904be439-79b3-403e-a1df-73e1ee5cd3b1)
![image](https://github.com/user-attachments/assets/b399aa2b-f979-4608-a0b1-66d5ff51975b)

### CIFAR10
![image](https://github.com/user-attachments/assets/17c9685c-9663-4d6c-9c61-4ed84f2e1fb3)
![image](https://github.com/user-attachments/assets/f79b05bf-7cfa-44f0-b703-069aa0cb0d50)


</details>

### 5.2Â Â Fashionâ€‘MNIST (10Â classes, 28Ã—28Â gray)

| Metric                     |    NdLinear |
| -------------------------- | ----------: |
| **Params**                 |     128â€¯154 |
| **Best acc.**              | **92.16â€¯%** |
| **AvgÂ epochÂ time**         |      7.28â€¯s |
| **AvgÂ GPUÂ mem**            |     0.04Â MB |
| **EpochsÂ toÂ 90â€¯%Â of best** |       **1** |

*A baseline was not rerun for Fashionâ€‘MNIST; literature baselines at similar capacity typically scoreÂ âˆ¼91â€¯%.*

---

## 6Â Â Key Takeaways

1. **Parameter efficiency:** NdLinear slashes parameters by **>80â€¯%** on CIFARâ€‘10 with a small *increase* in accuracy.
2. **Memory footprint:** Thanks to fewer weights, peak GPU memory drops slightly; useful for edge devices.
3. **Speed:** Compute cost is almost unchanged (â‰¤â€¯0.02â€¯s per epoch difference on T4).
4. **Convergence:** NdLinear may require one extra epoch to reach steady accuracy but still converges rapidly.
5. **Generalisation:** High 92â€¯%+ accuracy on Fashionâ€‘MNIST demonstrates robustness across datasets.

---

## 7Â Â Reproducing & Extending

```python
# Example: Load saved metrics without retraining
import pickle
with open("results/cifar10_comparison_results.pkl", "rb") as f:
    data = pickle.load(f)
print(data.keys())  # train_losses, test_accs, ...
```

Feel free to:

* Swap in **ResNet** or **MobileNet** backbones to test NdLinear at scale.
* Tune `rank` inside NdLinear for an accuracyâ€‘vsâ€‘parameters Pareto sweep.
* Add pruning or quantisation for further compression.

---

## 8Â Â References

* *NdLinear: Lowâ€‘Rank Linear Layer for Efficient Vision Models* â€“ original paper & code<br>
* **PyTorch** & **Torchvision** for training loops<br>
* **Fashionâ€‘MNIST** & **CIFARâ€‘10** datasets 
---

> Â©Â 2025Â YashÂ NayiÂ Â Ensemble AI
> Special Thanks to Alex anf Zach
