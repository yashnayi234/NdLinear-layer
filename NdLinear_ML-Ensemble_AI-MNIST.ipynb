{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55BqXcwWNjRF",
    "outputId": "330c2d7e-3797-44b0-fe2d-964cadf1a9ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "# !git clone https://github.com/ensemble-core/NdLinear.git\n",
    "# !cd NdLinear\n",
    "# !pip install .\n",
    "# !pip install ndlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWigusJJ7K9Z",
    "outputId": "96f95c4c-8c8b-465a-86f0-9e50260dad3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchprofile in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (0.0.4)\n",
      "Requirement already satisfied: psutil in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (7.0.0)\n",
      "Requirement already satisfied: filelock in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install ndlinear --ignore-requires-python\n",
    "!pip install torch torchvision torchprofile psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alQQnsqI3tGJ",
    "outputId": "e7510cf4-9256-4478-b7a7-f5e0c65a6bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.2\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "U11JgGsX4hMf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/saphp@cfreg.local/miniconda3/envs/ModelLLM/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "0YHJP4MCYb0M"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ndlinear import NdLinear\n",
    "from torchprofile import profile_macs\n",
    "import psutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfoho-lp3jfr"
   },
   "source": [
    "# Load and Prepare Dataset\n",
    "- Use MNIST for simplicity (28x28 grayscale images, 10 classes).\n",
    "- Code to load and preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ETJ_UjQHZLbr"
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_loader_256 = torch.utils.data.DataLoader(dataset=testset, batch_size=256, shuffle=False)\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.2860,), (0.3530,))])\n",
    "# train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "# test_loader_256 = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.286,), std=(0.353,))\n",
       "           )"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc-bAKT31gYm"
   },
   "source": [
    "# Define Models\n",
    "\n",
    "- Baseline Model: A CNN with nn.Linear layers.\n",
    "- NdLinear Model: Same architecture, swapping nn.Linear with NdLinear.\n",
    "- Sample CNN (2 conv layers + 2 linear layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight CNN with a single linear layer:\n",
    "      (3, 32, 32) -> Conv(3->16) -> Pool -> Linear(4096->512) -> FC(512->10)\n",
    "    \"\"\"\n",
    "    def __init__(self, out_dim=10, dropout_rate=0.3):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear = nn.Linear(16 * 16 * 16, 512)  # 16 * 16 * 16 = 4096\n",
    "        self.bn_linear = nn.BatchNorm1d(512)\n",
    "        self.fc = nn.Linear(512, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, 32, 32)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # (B, 16, 16, 16)\n",
    "        x = x.view(x.size(0), -1)  # (B, 4096)\n",
    "        x = F.relu(self.bn_linear(self.linear(x)))  # (B, 512)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # (B, 10)\n",
    "        return x\n",
    "\n",
    "# NdLinearCNN for CIFAR-100\n",
    "class NdLinearCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight CNN with a single NdLinear layer:\n",
    "      (3, 32, 32) -> Conv(3->16) -> Pool -> NdLinear((16,16,16)->(8,8,8)) -> FC(512->10)\n",
    "    \"\"\"\n",
    "    def __init__(self, out_dim=10, dropout_rate=0.3):\n",
    "        super(NdLinearCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.nd = NdLinear(in_shape=(16, 16, 16), out_shape=(8, 8, 8))  # 8*8*8 = 512\n",
    "        self.bn_nd = nn.BatchNorm2d(8)\n",
    "        self.fc = nn.Linear(512, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, 32, 32)\n",
    "        batch_size = x.size(0)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # (B, 16, 16, 16)\n",
    "        x = self.nd(x.contiguous().view(batch_size, 16, 16, 16))  # (B, 8, 8, 8)\n",
    "        x = F.relu(self.bn_nd(x))\n",
    "        x = x.view(x.shape[0], -1)  # (B, 512)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # (B, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUuPORyM1rC6"
   },
   "source": [
    "# Train and Evaluate\n",
    "- Train both models for a few epochs (e.g., 5) to compare performance.\n",
    "- Track accuracy, parameter count, and inference time.\n",
    "- Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "3DkpRJZoZQ0A",
    "outputId": "961af4fa-7b91-4667-ce24-a3716ae3e093"
   },
   "outputs": [],
   "source": [
    "# Custom weight initialization for NdLinear\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, NdLinear):\n",
    "#         for layer in m.align_layers:\n",
    "#             nn.init.orthogonal_(layer.weight)\n",
    "#             if layer.bias is not None:\n",
    "#                 nn.init.zeros_(layer.bias)\n",
    "                \n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=8):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    model.train()\n",
    "    # model.apply(init_weights)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_acc = evaluate_model(model, test_loader)\n",
    "        print(f'Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    return avg_loss, test_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Parameter counting\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "# Memory usage measurement\n",
    "def measure_memory_usage(model, test_loader):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    process = psutil.Process()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            model(images)\n",
    "            memory = process.memory_info().rss / 1024 / 1024\n",
    "            break\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN models...\n",
      "\n",
      "BaselineCNN:\n",
      "Epoch [1/8], Loss: 0.3650, Train Acc: 86.65%\n",
      "Test Acc: 89.84%\n",
      "Epoch [2/8], Loss: 0.2396, Train Acc: 91.10%\n",
      "Test Acc: 90.70%\n",
      "Epoch [3/8], Loss: 0.1930, Train Acc: 92.83%\n",
      "Test Acc: 91.76%\n",
      "Epoch [4/8], Loss: 0.1356, Train Acc: 95.01%\n",
      "Test Acc: 92.39%\n",
      "Epoch [5/8], Loss: 0.1138, Train Acc: 95.79%\n",
      "Test Acc: 92.67%\n",
      "Epoch [6/8], Loss: 0.0931, Train Acc: 96.60%\n",
      "Test Acc: 91.85%\n",
      "Epoch [7/8], Loss: 0.0588, Train Acc: 98.01%\n",
      "Test Acc: 93.07%\n",
      "Epoch [8/8], Loss: 0.0454, Train Acc: 98.53%\n",
      "Test Acc: 93.06%\n",
      "\n",
      "NdLinearCNN:\n",
      "Epoch [1/8], Loss: 0.4582, Train Acc: 84.07%\n",
      "Test Acc: 87.67%\n",
      "Epoch [2/8], Loss: 0.2864, Train Acc: 89.60%\n",
      "Test Acc: 89.12%\n",
      "Epoch [3/8], Loss: 0.2493, Train Acc: 91.05%\n",
      "Test Acc: 90.19%\n",
      "Epoch [4/8], Loss: 0.2066, Train Acc: 92.65%\n",
      "Test Acc: 90.83%\n",
      "Epoch [5/8], Loss: 0.1940, Train Acc: 93.01%\n",
      "Test Acc: 90.94%\n",
      "Epoch [6/8], Loss: 0.1838, Train Acc: 93.53%\n",
      "Test Acc: 90.43%\n",
      "Epoch [7/8], Loss: 0.1600, Train Acc: 94.35%\n",
      "Test Acc: 91.45%\n",
      "Epoch [8/8], Loss: 0.1522, Train Acc: 94.64%\n",
      "Test Acc: 91.18%\n",
      "\n",
      "Baseline CNN - Acc: 93.06%, Params: 1631306, GFLOPs: 2.81, Memory: 1603.24 MB\n",
      "NdLinear CNN - Acc: 91.18%, Params: 30506, GFLOPs: 2.15, Memory: 1603.24 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation loop\n",
    "models = [\n",
    "    (BaselineCNN_1M, NdLinearCNN_1M, \"CNN\"),\n",
    "    # Add (BaselineCNN_3M, NdLinearCNN_3M, \"3M\") and (BaselineCNN_5M, NdLinearCNN_5M, \"5M\") as needed\n",
    "]\n",
    "\n",
    "baseline_accs, ndlinear_accs = [], []\n",
    "baseline_params, ndlinear_params = [], []\n",
    "baseline_gflops, ndlinear_gflops = [], []\n",
    "baseline_memory, ndlinear_memory = [], []\n",
    "\n",
    "for baseline_cls, ndlinear_cls, size in models:\n",
    "    print(f\"\\nTraining {size} models...\")\n",
    "    \n",
    "    # Baseline model\n",
    "    baseline_model = baseline_cls()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    baseline_optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
    "    print(\"\\nBaselineCNN:\")\n",
    "    baseline_loss, baseline_acc = train_model(baseline_model, train_loader, test_loader, criterion, baseline_optimizer)\n",
    "    \n",
    "    # NdLinear model\n",
    "    ndlinear_model = ndlinear_cls()\n",
    "    ndlinear_optimizer = optim.Adam(ndlinear_model.parameters(), lr=0.001)\n",
    "    # ndlinear_optimizer = optim.Adam([\n",
    "    #     {'params': conv_bn_params, 'lr': 0.001},\n",
    "    #     {'params': ndlinear_params_list, 'lr': 0.001}\n",
    "    # ])\n",
    "    print(\"\\nNdLinearCNN:\")\n",
    "    ndlinear_loss, ndlinear_acc = train_model(ndlinear_model, train_loader, test_loader, criterion, ndlinear_optimizer)\n",
    "    \n",
    "    # Metrics\n",
    "    baseline_param = count_parameters(baseline_model)\n",
    "    ndlinear_param = count_parameters(ndlinear_model)\n",
    "    baseline_mem = measure_memory_usage(baseline_model, test_loader)\n",
    "    ndlinear_mem = measure_memory_usage(ndlinear_model, test_loader)\n",
    "    \n",
    "    baseline_accs.append(baseline_acc)\n",
    "    ndlinear_accs.append(ndlinear_acc)\n",
    "    baseline_params.append(baseline_param)\n",
    "    ndlinear_params.append(ndlinear_param)\n",
    "    baseline_memory.append(baseline_mem)\n",
    "    ndlinear_memory.append(ndlinear_mem)\n",
    "    \n",
    "    print(f\"\\nBaseline {size} - Acc: {baseline_acc:.2f}%, Params: {baseline_param}, GFLOPs: {baseline_gflop:.2f}, Memory: {baseline_mem:.2f} MB\")\n",
    "    print(f\"NdLinear {size} - Acc: {ndlinear_acc:.2f}%, Params: {ndlinear_param}, GFLOPs: {ndlinear_gflop:.2f}, Memory: {ndlinear_mem:.2f} MB\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFEvZmx41xtr"
   },
   "source": [
    "# Measure Metrics\n",
    "- Parameter Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY8vZGLfZQ6A",
    "outputId": "00ed4409-483c-4e05-ab72-02f123a6a136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Parameters: 1631306\n",
      "NdLinear Parameters: 30506\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Parameters: {count_parameters(baseline_model)}')\n",
    "print(f'NdLinear Parameters: {count_parameters(ndlinear_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8dPxGLu9kbI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
